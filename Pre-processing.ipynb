{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\rpy2\\robjects\\pandas2ri.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import Index as PandasIndex\n"
     ]
    }
   ],
   "source": [
    "import rpy2.ipython\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%R require(ggplot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([df.combo].mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas_profiling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "\n",
    "#data = pd.read_excel (r'neonatal/neonatal outcomes.xlsx')\n",
    "df = pd.read_excel('neonatal/neonatal outcomes.xlsx', engine='openpyxl')\n",
    "\n",
    "\n",
    "profile = ProfileReport(df, title=\"Pandas Profiling Report\")\n",
    "\n",
    "profile.to_file(\"output.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sweetviz as sv\n",
    "#analyzing the dataset\n",
    "car_report = sv.analyze(df)\n",
    "car_report.show_html('Report.html')\n",
    "#Analyzing a single dataframe (and its -optional- target feature)\n",
    "my_report = sv.analyze([train, \"Train\"],target_feat='SalePrice')\n",
    "my_report.show_html('Report.html')\n",
    "#Comparing two dataframes (e.g. Test vs Training sets)\n",
    "my_report1 = sv.compare([train, \"Train\"], [test, \"Test\"], \"SalePrice\")\n",
    "my_report1.show_html('Report.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import IPython\n",
    "IPython.display.HTML('Report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliners\n",
    "max_thresold = df['height'].quantile(0.95)\n",
    "min_thresold = df['height'].quantile(0.05)\n",
    "df = df[(df['height']<max_thresold) & (df['height']>min_thresold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FeatureSelector \n",
    "\n",
    "# Delelte duplicate features\n",
    "unique_df = data_t.drop_duplicates(keep='first').T\n",
    "unique_df.shape\n",
    "\n",
    "# feature selection\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "X, y = load_digits(return_X_y=True)\n",
    "X.shape\n",
    "(1797, 64)\n",
    "X_new = SelectKBest(chi2, k=20).fit_transform(X, y)\n",
    "X_new.shape\n",
    "\n",
    "\n",
    "# Missing Values\n",
    "from feature_selector import FeatureSelector\n",
    "fs = FeatureSelector(data = X, labels = train_labels)\n",
    "fs.identify_missing(missing_threshold=0.6)\n",
    "missing_features = fs.ops['missing']\n",
    "missing_features[:10]\n",
    "fs.plot_missing()\n",
    "\n",
    "\n",
    "# Collinear Features\n",
    "fs.identify_collinear(correlation_threshold=0.975)\n",
    "correlated_features = fs.ops['collinear']\n",
    "correlated_features[:5]\n",
    "fs.plot_collinear()\n",
    "fs.record_collinear.head()\n",
    "\n",
    "# Zero Importance Features\n",
    "fs.identify_zero_importance(task = 'classification', eval_metric = 'auc', \n",
    "                            n_iterations = 10, early_stopping = True)\n",
    "fs.plot_feature_importances(threshold = 0.99, plot_n = 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensionality reduction using pca\n",
    "# البتاع ده بيقلل الvariance\n",
    "# لازم أختار عدد يحافظ على 95% من الفاريانس على الأقل\n",
    "data = ...\n",
    "# define transform\n",
    "pca = PCA()\n",
    "# prepare transform on dataset\n",
    "pca.fit(data)\n",
    "# apply transform to dataset\n",
    "transformed = pca.transform(data)\n",
    "# define the pipeline\n",
    "steps = [('pca', PCA()), ('m', LogisticRegression())]\n",
    "model = Pipeline(steps=steps)\n",
    "# test classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate pca with logistic regression algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "# define the pipeline\n",
    "steps = [('pca', PCA(n_components=10)), ('m', LogisticRegression())]\n",
    "model = Pipeline(steps=steps)\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word to num\n",
    "from word2number import w2n\n",
    "df.x = x2n.word_to_num(df.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEROID(S) One hot encoding\n",
    "#steroids_dum=pd.get_dummies(df.steroids)\n",
    "#steroids_dum.columns = ['steroids1', 'steroids2', 'steroids3']\n",
    "#df_M = pd.concat([df,steroids_dum],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze how many null values are in the dataset\n",
    "import math\n",
    "#data.isnull().sum()\n",
    "# data.plot_missing()\n",
    "\n",
    "# drop all missing values in all columns:\n",
    "#data = data.dropna()\n",
    "\n",
    "# Mean value imputation:\n",
    "# data[\"Age\"].fillna(data[\"Age\"].mean(), inplace=True)\n",
    "\n",
    "# Check the database after missed data were dropped\n",
    "#data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#get correlations of each features in dataset\n",
    "corrmat = data.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(50,50))\n",
    "#plot heat map\n",
    "g=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implanced data\n",
    "ones = data[data['Class']==1]\n",
    "zeros = data[data['Class']==0]\n",
    "print(ones.shape,zeros.shape)\n",
    "# لو طلع في فرق بين الرقمين\n",
    "\n",
    "\n",
    "# Implementing Undersampling بياخد عينة عشوائية من المجموعة الكبيرة\n",
    "nm = NearMiss(random_state=42)\n",
    "X_res,y_res=nm.fit_sample(X,Y)\n",
    "\n",
    "# Implementing Oversampling (شبه البوتستراب)\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import NearMiss\n",
    "smk = SMOTETomek(random_state=42)\n",
    "X_res,y_res=smk.fit_sample(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Composite Outcome\n",
    "#C_outcome = df['neonatal_morbidity'] + df ['perinatal_death'] + df['nicu_admission'] + df['resp_support'] + df['apgar_5']\n",
    "#C_outcome = C_outcome.replace([2,3,4,5],1)\n",
    "#C_outcome.columns = ['C_outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some algorithms work better with normalization\n",
    "Features =  np.asarray(df_final[['age', 'parity', 'bmi', 'smoking',\n",
    "                           'race3', 'race4', \n",
    "                           'prev_cs', 'ivf', 'conception_type','gdm', 'pregdm', 'htn', 'ghtn', 'chtn', 'pree', 'iugr',\n",
    "                           'gyn_dc', 'ob_dc', 'ga_diagnosis', 'method1', 'method2', 'method3', \n",
    "                           'ga_deliver', 'steroid',\n",
    "                           'pre_hgb', 'site1', 'site2', 'site3', 'site4', 'site5', \n",
    "                           'incision1', 'incision2', 'incision3',  \n",
    "                           'incision_placenta', 'pre_us', 'intra_us',\n",
    "                           'organ_invasion', \n",
    "                           'cord_clamp', 'planned']])\n",
    "\n",
    "# Name every outcome differently"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
